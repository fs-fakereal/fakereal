{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19461d25-27da-4aa1-9472-c19e46cdca54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /home/liam/Code/school/fakereal/.venv/lib/python3.12/site-packages (24.3.1)\n",
      "Collecting pip\n",
      "  Using cached pip-25.0.1-py3-none-any.whl.metadata (3.7 kB)\n",
      "Using cached pip-25.0.1-py3-none-any.whl (1.8 MB)\n",
      "Installing collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 24.3.1\n",
      "    Uninstalling pip-24.3.1:\n",
      "      Successfully uninstalled pip-24.3.1\n",
      "Successfully installed pip-25.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73cdd57c-0814-4d76-a1c1-a3e215eaa046",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /home/liam/Code/school/fakereal/.venv/lib/python3.12/site-packages (2.19.0)\n",
      "Collecting pandas\n",
      "  Using cached pandas-2.2.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
      "Requirement already satisfied: numpy in /home/liam/Code/school/fakereal/.venv/lib/python3.12/site-packages (2.1.3)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /home/liam/Code/school/fakereal/.venv/lib/python3.12/site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/liam/Code/school/fakereal/.venv/lib/python3.12/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /home/liam/Code/school/fakereal/.venv/lib/python3.12/site-packages (from tensorflow) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /home/liam/Code/school/fakereal/.venv/lib/python3.12/site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/liam/Code/school/fakereal/.venv/lib/python3.12/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /home/liam/Code/school/fakereal/.venv/lib/python3.12/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/liam/Code/school/fakereal/.venv/lib/python3.12/site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in /home/liam/Code/school/fakereal/.venv/lib/python3.12/site-packages (from tensorflow) (24.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /home/liam/Code/school/fakereal/.venv/lib/python3.12/site-packages (from tensorflow) (5.29.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/liam/Code/school/fakereal/.venv/lib/python3.12/site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in /home/liam/Code/school/fakereal/.venv/lib/python3.12/site-packages (from tensorflow) (76.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/liam/Code/school/fakereal/.venv/lib/python3.12/site-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/liam/Code/school/fakereal/.venv/lib/python3.12/site-packages (from tensorflow) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/liam/Code/school/fakereal/.venv/lib/python3.12/site-packages (from tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /home/liam/Code/school/fakereal/.venv/lib/python3.12/site-packages (from tensorflow) (1.17.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/liam/Code/school/fakereal/.venv/lib/python3.12/site-packages (from tensorflow) (1.71.0)\n",
      "Requirement already satisfied: tensorboard~=2.19.0 in /home/liam/Code/school/fakereal/.venv/lib/python3.12/site-packages (from tensorflow) (2.19.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in /home/liam/Code/school/fakereal/.venv/lib/python3.12/site-packages (from tensorflow) (3.9.0)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /home/liam/Code/school/fakereal/.venv/lib/python3.12/site-packages (from tensorflow) (3.13.0)\n",
      "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /home/liam/Code/school/fakereal/.venv/lib/python3.12/site-packages (from tensorflow) (0.5.1)\n",
      "Collecting python-dateutil>=2.8.2 (from pandas)\n",
      "  Using cached python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Using cached pytz-2025.1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Using cached tzdata-2025.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /home/liam/Code/school/fakereal/.venv/lib/python3.12/site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: rich in /home/liam/Code/school/fakereal/.venv/lib/python3.12/site-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
      "Requirement already satisfied: namex in /home/liam/Code/school/fakereal/.venv/lib/python3.12/site-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in /home/liam/Code/school/fakereal/.venv/lib/python3.12/site-packages (from keras>=3.5.0->tensorflow) (0.14.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/liam/Code/school/fakereal/.venv/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/liam/Code/school/fakereal/.venv/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/liam/Code/school/fakereal/.venv/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/liam/Code/school/fakereal/.venv/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/liam/Code/school/fakereal/.venv/lib/python3.12/site-packages (from tensorboard~=2.19.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/liam/Code/school/fakereal/.venv/lib/python3.12/site-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/liam/Code/school/fakereal/.venv/lib/python3.12/site-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/liam/Code/school/fakereal/.venv/lib/python3.12/site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/liam/Code/school/fakereal/.venv/lib/python3.12/site-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/liam/Code/school/fakereal/.venv/lib/python3.12/site-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/liam/Code/school/fakereal/.venv/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
      "Using cached pandas-2.2.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.7 MB)\n",
      "Using cached python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
      "Using cached pytz-2025.1-py2.py3-none-any.whl (507 kB)\n",
      "Using cached tzdata-2025.1-py2.py3-none-any.whl (346 kB)\n",
      "Installing collected packages: pytz, tzdata, python-dateutil, pandas\n",
      "Successfully installed pandas-2.2.3 python-dateutil-2.9.0.post0 pytz-2025.1 tzdata-2025.1\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow pandas numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80cac0fb-de69-4d34-b284-cd5a1be3d905",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-18 10:56:17.742963: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications import VGG16, MobileNetV3Small\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D, Input, BatchNormalization\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.metrics import BinaryAccuracy, F1Score\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.train import latest_checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24f8b2b5-fc3e-4f22-a853-002243cd3fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"mobilenetv3small\"\n",
    "img_size = 256 # assume same for both width and height\n",
    "batch_size = 8\n",
    "\n",
    "data_dir = \"data\"\n",
    "output_dir = \"output\"\n",
    "# assume there is a json file of the same name inside these data subdirs.\n",
    "\n",
    "checkpoint_dir = \"checkpoints\"\n",
    "checkpoint_path = f\"{checkpoint_dir}/{model_name}/\" + \"cp-{epoch:04d}.weights.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "01bae064-7dea-460f-9c22-1082f2f806d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train: pd.DataFrame = pd.read_csv(f\"{data_dir}/uniface-ff-train.csv\")\n",
    "df_val: pd.DataFrame = pd.read_csv(f\"{data_dir}/uniface-ff-test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3d25c781-940b-4602-9d59-8e05a7d85d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['label'] = df_train['label'].astype('str')\n",
    "df_val['label'] = df_val['label'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d8760e8e-72a8-4de3-b329-fb3a33cb51d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 22993 validated image filenames belonging to 1 classes.\n",
      "Found 4479 validated image filenames belonging to 1 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\scout\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\legacy\\preprocessing\\image.py:920: UserWarning: Found 11794 invalid image filename(s) in x_col=\"filepath\". These filename(s) will be ignored.\n",
      "  warnings.warn(\n",
      "C:\\Users\\scout\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\legacy\\preprocessing\\image.py:920: UserWarning: Found 4465 invalid image filename(s) in x_col=\"filepath\". These filename(s) will be ignored.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=(1./255),\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    brightness_range=[-0.5, 0.5],\n",
    "    rotation_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    df_train,\n",
    "    x_col = \"filepath\",\n",
    "    y_col = \"label\",\n",
    "    target_size=(img_size, img_size),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary',\n",
    "    validate_filenames=True\n",
    ")\n",
    "val_generator = val_datagen.flow_from_dataframe(\n",
    "    df_val,\n",
    "    x_col = \"filepath\",\n",
    "    y_col = \"label\",\n",
    "    target_size=(img_size, img_size),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary',\n",
    "    validate_filenames=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2bbca939-2519-4e6e-b3b5-61e7f5795a4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                          </span>┃<span style=\"font-weight: bold\"> Output Shape                  </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Traina… </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━┩\n",
       "│ input_layer_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │    <span style=\"font-weight: bold\">-</span>    │\n",
       "├───────────────────────────────────────┼───────────────────────────────┼────────────────┼─────────┤\n",
       "│ vgg16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)             │     <span style=\"color: #00af00; text-decoration-color: #00af00\">14,714,688</span> │    <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">N</span>    │\n",
       "├───────────────────────────────────────┼───────────────────────────────┼────────────────┼─────────┤\n",
       "│ global_average_pooling2d_3            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │    <span style=\"font-weight: bold\">-</span>    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)              │                               │                │         │\n",
       "├───────────────────────────────────────┼───────────────────────────────┼────────────────┼─────────┤\n",
       "│ batch_normalization_2                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │    <span style=\"color: #00af00; text-decoration-color: #00af00; font-weight: bold\">Y</span>    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                  │                               │                │         │\n",
       "├───────────────────────────────────────┼───────────────────────────────┼────────────────┼─────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │    <span style=\"font-weight: bold\">-</span>    │\n",
       "├───────────────────────────────────────┼───────────────────────────────┼────────────────┼─────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                     │            <span style=\"color: #00af00; text-decoration-color: #00af00\">513</span> │    <span style=\"color: #00af00; text-decoration-color: #00af00; font-weight: bold\">Y</span>    │\n",
       "└───────────────────────────────────────┴───────────────────────────────┴────────────────┴─────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                         \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mTraina…\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━┩\n",
       "│ input_layer_7 (\u001b[38;5;33mInputLayer\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m3\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │    \u001b[1m-\u001b[0m    │\n",
       "├───────────────────────────────────────┼───────────────────────────────┼────────────────┼─────────┤\n",
       "│ vgg16 (\u001b[38;5;33mFunctional\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m512\u001b[0m)             │     \u001b[38;5;34m14,714,688\u001b[0m │    \u001b[1;91mN\u001b[0m    │\n",
       "├───────────────────────────────────────┼───────────────────────────────┼────────────────┼─────────┤\n",
       "│ global_average_pooling2d_3            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                   │              \u001b[38;5;34m0\u001b[0m │    \u001b[1m-\u001b[0m    │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)              │                               │                │         │\n",
       "├───────────────────────────────────────┼───────────────────────────────┼────────────────┼─────────┤\n",
       "│ batch_normalization_2                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                   │          \u001b[38;5;34m2,048\u001b[0m │    \u001b[1;38;5;34mY\u001b[0m    │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                  │                               │                │         │\n",
       "├───────────────────────────────────────┼───────────────────────────────┼────────────────┼─────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                   │              \u001b[38;5;34m0\u001b[0m │    \u001b[1m-\u001b[0m    │\n",
       "├───────────────────────────────────────┼───────────────────────────────┼────────────────┼─────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                     │            \u001b[38;5;34m513\u001b[0m │    \u001b[1;38;5;34mY\u001b[0m    │\n",
       "└───────────────────────────────────────┴───────────────────────────────┴────────────────┴─────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">14,717,249</span> (56.14 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m14,717,249\u001b[0m (56.14 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,537</span> (6.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,537\u001b[0m (6.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">14,715,712</span> (56.14 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m14,715,712\u001b[0m (56.14 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pretrained_model = MobileNetV3Small(\n",
    "    weights='imagenet',\n",
    "    include_top=False,\n",
    "    input_shape=(img_size, img_size, 3)\n",
    ")\n",
    "\n",
    "pretrained_model.trainable = False\n",
    "\n",
    "# technique to \"stack\" layers, starting with pretrain model's layers\n",
    "inputs = Input(shape=(img_size, img_size, 3))\n",
    "\n",
    "cl = pretrained_model(inputs, training=False)\n",
    "\n",
    "cl = GlobalAveragePooling2D()(cl)\n",
    "cl = BatchNormalization()(cl)\n",
    "cl = Dropout(0.2)(cl)\n",
    "\n",
    "# this is the final layer; size must equal desired output size\n",
    "outputs = Dense(1, activation='sigmoid')(cl)\n",
    "model = Model(inputs, outputs)\n",
    "\n",
    "model.summary(show_trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "cd8c4245-b9b5-4f6e-9b14-2d3a6254a0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "learning_rate = 1e-6\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate),\n",
    "    loss=BinaryCrossentropy(from_logits=False),\n",
    "    metrics=[BinaryAccuracy()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "cc7733d2-f771-4e44-a83d-100f9aecda12",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_callback = ModelCheckpoint(\n",
    "    filepath=os.path.join(os.getcwd(), checkpoint_path),\n",
    "    save_weights_only=True,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "113d2a51-b77d-48e8-b8fd-bc0615302664",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'latest_checkpoint' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m latest = \u001b[43mlatest_checkpoint\u001b[49m(os.path.join(os.getcwd(), checkpoint_path))\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(latest)\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m#model.load_weights(latest)\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'latest_checkpoint' is not defined"
     ]
    }
   ],
   "source": [
    "latest = latest_checkpoint(os.path.join(os.getcwd(), checkpoint_path))\n",
    "print(latest)\n",
    "#model.load_weights(latest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c573bfc9-c7a5-41f4-95bf-5df02f324140",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\scout\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m2874/2874\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 664ms/step - binary_accuracy: 0.5362 - loss: 0.7131   \n",
      "Epoch 1: saving model to D:\\scout\\Code\\fakereal\\models\\checkpoints/vgg16/cp-0001.weights.h5\n",
      "\u001b[1m2874/2874\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2267s\u001b[0m 789ms/step - binary_accuracy: 0.5362 - loss: 0.7131 - val_binary_accuracy: 0.5693 - val_loss: 0.8077\n",
      "Epoch 2/10\n",
      "\u001b[1m   1/2874\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m32:48\u001b[0m 685ms/step - binary_accuracy: 0.5000 - loss: 0.7571"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\scout\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\epoch_iterator.py:107: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self._interrupted_warning()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2: saving model to D:\\scout\\Code\\fakereal\\models\\checkpoints/vgg16/cp-0002.weights.h5\n",
      "\u001b[1m2874/2874\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m348s\u001b[0m 121ms/step - binary_accuracy: 0.5000 - loss: 0.7571 - val_binary_accuracy: 0.5686 - val_loss: 0.8086\n",
      "Epoch 3/10\n",
      "\u001b[1m2874/2874\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 618ms/step - binary_accuracy: 0.6411 - loss: 0.6722   \n",
      "Epoch 3: saving model to D:\\scout\\Code\\fakereal\\models\\checkpoints/vgg16/cp-0003.weights.h5\n",
      "\u001b[1m2874/2874\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2104s\u001b[0m 732ms/step - binary_accuracy: 0.6412 - loss: 0.6722 - val_binary_accuracy: 0.6713 - val_loss: 0.6240\n",
      "Epoch 4/10\n",
      "\u001b[1m   1/2874\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m28:15\u001b[0m 590ms/step - binary_accuracy: 0.6250 - loss: 0.6251\n",
      "Epoch 4: saving model to D:\\scout\\Code\\fakereal\\models\\checkpoints/vgg16/cp-0004.weights.h5\n",
      "\u001b[1m2874/2874\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m329s\u001b[0m 114ms/step - binary_accuracy: 0.6250 - loss: 0.6251 - val_binary_accuracy: 0.6729 - val_loss: 0.6213\n",
      "Epoch 5/10\n",
      "\u001b[1m2874/2874\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 607ms/step - binary_accuracy: 0.7286 - loss: 0.6318   \n",
      "Epoch 5: saving model to D:\\scout\\Code\\fakereal\\models\\checkpoints/vgg16/cp-0005.weights.h5\n",
      "\u001b[1m2874/2874\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2094s\u001b[0m 729ms/step - binary_accuracy: 0.7286 - loss: 0.6318 - val_binary_accuracy: 0.7200 - val_loss: 0.5400\n",
      "Epoch 6/10\n",
      "\u001b[1m   1/2874\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m29:13\u001b[0m 610ms/step - binary_accuracy: 0.8750 - loss: 0.5416\n",
      "Epoch 6: saving model to D:\\scout\\Code\\fakereal\\models\\checkpoints/vgg16/cp-0006.weights.h5\n",
      "\u001b[1m2874/2874\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m346s\u001b[0m 120ms/step - binary_accuracy: 0.8750 - loss: 0.5416 - val_binary_accuracy: 0.7174 - val_loss: 0.5439\n",
      "Epoch 7/10\n",
      "\u001b[1m2874/2874\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 641ms/step - binary_accuracy: 0.8003 - loss: 0.5943   \n",
      "Epoch 7: saving model to D:\\scout\\Code\\fakereal\\models\\checkpoints/vgg16/cp-0007.weights.h5\n",
      "\u001b[1m2874/2874\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2181s\u001b[0m 759ms/step - binary_accuracy: 0.8003 - loss: 0.5943 - val_binary_accuracy: 0.7446 - val_loss: 0.4997\n",
      "Epoch 8/10\n",
      "\u001b[1m   1/2874\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m32:44\u001b[0m 684ms/step - binary_accuracy: 0.6250 - loss: 0.5558\n",
      "Epoch 8: saving model to D:\\scout\\Code\\fakereal\\models\\checkpoints/vgg16/cp-0008.weights.h5\n",
      "\u001b[1m2874/2874\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m352s\u001b[0m 122ms/step - binary_accuracy: 0.6250 - loss: 0.5558 - val_binary_accuracy: 0.7469 - val_loss: 0.4971\n",
      "Epoch 9/10\n",
      "\u001b[1m2874/2874\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 605ms/step - binary_accuracy: 0.8520 - loss: 0.5602   \n",
      "Epoch 9: saving model to D:\\scout\\Code\\fakereal\\models\\checkpoints/vgg16/cp-0009.weights.h5\n",
      "\u001b[1m2874/2874\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2062s\u001b[0m 717ms/step - binary_accuracy: 0.8520 - loss: 0.5602 - val_binary_accuracy: 0.7775 - val_loss: 0.4506\n",
      "Epoch 10/10\n",
      "\u001b[1m   1/2874\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m28:05\u001b[0m 587ms/step - binary_accuracy: 0.8750 - loss: 0.5417\n",
      "Epoch 10: saving model to D:\\scout\\Code\\fakereal\\models\\checkpoints/vgg16/cp-0010.weights.h5\n",
      "\u001b[1m2874/2874\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m326s\u001b[0m 113ms/step - binary_accuracy: 0.8750 - loss: 0.5417 - val_binary_accuracy: 0.7757 - val_loss: 0.4523\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=epochs,\n",
    "    steps_per_epoch=(train_generator.samples // train_generator.batch_size),\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=(val_generator.samples // val_generator.batch_size),\n",
    "    callbacks=[checkpoint_callback],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f08cb2-8c96-47e7-88e5-b11bfe2c52d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(val_generator, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "bcb72089-6fea-4933-bd0e-a4061c46072d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(f\"{output_dir}/deepfake-{model_name}.keras\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
