{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19461d25-27da-4aa1-9472-c19e46cdca54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in d:\\scout\\code\\fakereal\\.venv\\lib\\site-packages (25.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73cdd57c-0814-4d76-a1c1-a3e215eaa046",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in d:\\scout\\code\\fakereal\\.venv\\lib\\site-packages (2.19.0)\n",
      "Requirement already satisfied: pandas in d:\\scout\\code\\fakereal\\.venv\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy in d:\\scout\\code\\fakereal\\.venv\\lib\\site-packages (2.1.3)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in d:\\scout\\code\\fakereal\\.venv\\lib\\site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in d:\\scout\\code\\fakereal\\.venv\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in d:\\scout\\code\\fakereal\\.venv\\lib\\site-packages (from tensorflow) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in d:\\scout\\code\\fakereal\\.venv\\lib\\site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in d:\\scout\\code\\fakereal\\.venv\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in d:\\scout\\code\\fakereal\\.venv\\lib\\site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in d:\\scout\\code\\fakereal\\.venv\\lib\\site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in d:\\scout\\code\\fakereal\\.venv\\lib\\site-packages (from tensorflow) (24.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in d:\\scout\\code\\fakereal\\.venv\\lib\\site-packages (from tensorflow) (5.29.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in d:\\scout\\code\\fakereal\\.venv\\lib\\site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in d:\\scout\\code\\fakereal\\.venv\\lib\\site-packages (from tensorflow) (76.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in d:\\scout\\code\\fakereal\\.venv\\lib\\site-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in d:\\scout\\code\\fakereal\\.venv\\lib\\site-packages (from tensorflow) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in d:\\scout\\code\\fakereal\\.venv\\lib\\site-packages (from tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in d:\\scout\\code\\fakereal\\.venv\\lib\\site-packages (from tensorflow) (1.17.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in d:\\scout\\code\\fakereal\\.venv\\lib\\site-packages (from tensorflow) (1.71.0)\n",
      "Requirement already satisfied: tensorboard~=2.19.0 in d:\\scout\\code\\fakereal\\.venv\\lib\\site-packages (from tensorflow) (2.19.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in d:\\scout\\code\\fakereal\\.venv\\lib\\site-packages (from tensorflow) (3.9.0)\n",
      "Requirement already satisfied: h5py>=3.11.0 in d:\\scout\\code\\fakereal\\.venv\\lib\\site-packages (from tensorflow) (3.13.0)\n",
      "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in d:\\scout\\code\\fakereal\\.venv\\lib\\site-packages (from tensorflow) (0.5.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\scout\\code\\fakereal\\.venv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\scout\\code\\fakereal\\.venv\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in d:\\scout\\code\\fakereal\\.venv\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in d:\\scout\\code\\fakereal\\.venv\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: rich in d:\\scout\\code\\fakereal\\.venv\\lib\\site-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
      "Requirement already satisfied: namex in d:\\scout\\code\\fakereal\\.venv\\lib\\site-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in d:\\scout\\code\\fakereal\\.venv\\lib\\site-packages (from keras>=3.5.0->tensorflow) (0.14.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\scout\\code\\fakereal\\.venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\scout\\code\\fakereal\\.venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\scout\\code\\fakereal\\.venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\scout\\code\\fakereal\\.venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
      "Requirement already satisfied: markdown>=2.6.8 in d:\\scout\\code\\fakereal\\.venv\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in d:\\scout\\code\\fakereal\\.venv\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in d:\\scout\\code\\fakereal\\.venv\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in d:\\scout\\code\\fakereal\\.venv\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in d:\\scout\\code\\fakereal\\.venv\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in d:\\scout\\code\\fakereal\\.venv\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in d:\\scout\\code\\fakereal\\.venv\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow pandas numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80cac0fb-de69-4d34-b284-cd5a1be3d905",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications import VGG16, MobileNetV2\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D, Input, BatchNormalization\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.metrics import BinaryAccuracy, F1Score\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.train import latest_checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24f8b2b5-fc3e-4f22-a853-002243cd3fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"mobilenetv3small\"\n",
    "img_size = 256 # assume same for both width and height\n",
    "batch_size = 8\n",
    "\n",
    "data_dir = \"data\"\n",
    "output_dir = \"output\"\n",
    "# assume there is a json file of the same name inside these data subdirs.\n",
    "\n",
    "checkpoint_dir = \"checkpoints\"\n",
    "checkpoint_path = f\"{checkpoint_dir}/{model_name}/\" + \"cp-{epoch:04d}.weights.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01bae064-7dea-460f-9c22-1082f2f806d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train: pd.DataFrame = pd.read_csv(f\"{data_dir}/uniface-ff-train.csv\")\n",
    "df_val: pd.DataFrame = pd.read_csv(f\"{data_dir}/uniface-ff-test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d25c781-940b-4602-9d59-8e05a7d85d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['label'] = df_train['label'].astype('str')\n",
    "df_val['label'] = df_val['label'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2a67e44-eddc-40fc-bfaf-d48edd108172",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total failed validations:  11794\n"
     ]
    }
   ],
   "source": [
    "def validate_image_paths(df) -> int:\n",
    "\n",
    "    total: int = df.shape[0]\n",
    "\n",
    "    for path in df['filepath']:\n",
    "        if not os.path.exists(os.path.join(os.getcwd(), path)):\n",
    "            #print(\"failed to validate: \", path)\n",
    "            continue\n",
    "        total -= 1\n",
    "        \n",
    "    return total\n",
    "print(\"total failed validations: \", validate_image_paths(df_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d8760e8e-72a8-4de3-b329-fb3a33cb51d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 22993 validated image filenames belonging to 1 classes.\n",
      "Found 8944 validated image filenames belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\scout\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\legacy\\preprocessing\\image.py:920: UserWarning: Found 11794 invalid image filename(s) in x_col=\"filepath\". These filename(s) will be ignored.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=(1./255),\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    brightness_range=[-0.5, 0.5],\n",
    "    rotation_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    df_train,\n",
    "    x_col = \"filepath\",\n",
    "    y_col = \"label\",\n",
    "    target_size=(img_size, img_size),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary',\n",
    "    validate_filenames=True,\n",
    "    verbose=1,\n",
    ")\n",
    "val_generator = val_datagen.flow_from_dataframe(\n",
    "    df_val,\n",
    "    x_col = \"filepath\",\n",
    "    y_col = \"label\",\n",
    "    target_size=(img_size, img_size),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary',\n",
    "    validate_filenames=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2bbca939-2519-4e6e-b3b5-61e7f5795a4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\scout\\AppData\\Local\\Temp\\ipykernel_8940\\1930041350.py:1: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  pretrained_model = MobileNetV2(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                      </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">       Param # </span>┃<span style=\"font-weight: bold\"> Train… </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │   <span style=\"font-weight: bold\">-</span>    │\n",
       "├───────────────────────────────────┼───────────────────────────┼───────────────┼────────┤\n",
       "│ mobilenetv2_1.00_224 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,257,984</span> │   <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">N</span>    │\n",
       "├───────────────────────────────────┼───────────────────────────┼───────────────┼────────┤\n",
       "│ global_average_pooling2d          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │   <span style=\"font-weight: bold\">-</span>    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)          │                           │               │        │\n",
       "├───────────────────────────────────┼───────────────────────────┼───────────────┼────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)              │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,311,744</span> │   <span style=\"color: #00af00; text-decoration-color: #00af00; font-weight: bold\">Y</span>    │\n",
       "├───────────────────────────────────┼───────────────────────────┼───────────────┼────────┤\n",
       "│ batch_normalization               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │   <span style=\"color: #00af00; text-decoration-color: #00af00; font-weight: bold\">Y</span>    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)              │                           │               │        │\n",
       "├───────────────────────────────────┼───────────────────────────┼───────────────┼────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │   <span style=\"font-weight: bold\">-</span>    │\n",
       "├───────────────────────────────────┼───────────────────────────┼───────────────┼────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)              │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,049,600</span> │   <span style=\"color: #00af00; text-decoration-color: #00af00; font-weight: bold\">Y</span>    │\n",
       "├───────────────────────────────────┼───────────────────────────┼───────────────┼────────┤\n",
       "│ batch_normalization_1             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │   <span style=\"color: #00af00; text-decoration-color: #00af00; font-weight: bold\">Y</span>    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)              │                           │               │        │\n",
       "├───────────────────────────────────┼───────────────────────────┼───────────────┼────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │   <span style=\"font-weight: bold\">-</span>    │\n",
       "├───────────────────────────────────┼───────────────────────────┼───────────────┼────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,025</span> │   <span style=\"color: #00af00; text-decoration-color: #00af00; font-weight: bold\">Y</span>    │\n",
       "└───────────────────────────────────┴───────────────────────────┴───────────────┴────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mTrain…\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m3\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │   \u001b[1m-\u001b[0m    │\n",
       "├───────────────────────────────────┼───────────────────────────┼───────────────┼────────┤\n",
       "│ mobilenetv2_1.00_224 (\u001b[38;5;33mFunctional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m1280\u001b[0m)        │     \u001b[38;5;34m2,257,984\u001b[0m │   \u001b[1;91mN\u001b[0m    │\n",
       "├───────────────────────────────────┼───────────────────────────┼───────────────┼────────┤\n",
       "│ global_average_pooling2d          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)              │             \u001b[38;5;34m0\u001b[0m │   \u001b[1m-\u001b[0m    │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)          │                           │               │        │\n",
       "├───────────────────────────────────┼───────────────────────────┼───────────────┼────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)              │     \u001b[38;5;34m1,311,744\u001b[0m │   \u001b[1;38;5;34mY\u001b[0m    │\n",
       "├───────────────────────────────────┼───────────────────────────┼───────────────┼────────┤\n",
       "│ batch_normalization               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)              │         \u001b[38;5;34m4,096\u001b[0m │   \u001b[1;38;5;34mY\u001b[0m    │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)              │                           │               │        │\n",
       "├───────────────────────────────────┼───────────────────────────┼───────────────┼────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)              │             \u001b[38;5;34m0\u001b[0m │   \u001b[1m-\u001b[0m    │\n",
       "├───────────────────────────────────┼───────────────────────────┼───────────────┼────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)              │     \u001b[38;5;34m1,049,600\u001b[0m │   \u001b[1;38;5;34mY\u001b[0m    │\n",
       "├───────────────────────────────────┼───────────────────────────┼───────────────┼────────┤\n",
       "│ batch_normalization_1             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)              │         \u001b[38;5;34m4,096\u001b[0m │   \u001b[1;38;5;34mY\u001b[0m    │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)              │                           │               │        │\n",
       "├───────────────────────────────────┼───────────────────────────┼───────────────┼────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)              │             \u001b[38;5;34m0\u001b[0m │   \u001b[1m-\u001b[0m    │\n",
       "├───────────────────────────────────┼───────────────────────────┼───────────────┼────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                 │         \u001b[38;5;34m1,025\u001b[0m │   \u001b[1;38;5;34mY\u001b[0m    │\n",
       "└───────────────────────────────────┴───────────────────────────┴───────────────┴────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,628,545</span> (17.66 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,628,545\u001b[0m (17.66 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,366,465</span> (9.03 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,366,465\u001b[0m (9.03 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,262,080</span> (8.63 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,262,080\u001b[0m (8.63 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pretrained_model = MobileNetV2(\n",
    "    weights='imagenet',\n",
    "    include_top=False,\n",
    "    input_shape=(img_size, img_size, 3)\n",
    ")\n",
    "\n",
    "pretrained_model.trainable = False\n",
    "\n",
    "# technique to \"stack\" layers, starting with pretrain model's layers\n",
    "inputs = Input(shape=(img_size, img_size, 3))\n",
    "\n",
    "cl = pretrained_model(inputs, training=False)\n",
    "\n",
    "cl = GlobalAveragePooling2D()(cl)\n",
    "cl = Dense(1024, activation='relu')(cl)\n",
    "cl = BatchNormalization()(cl)\n",
    "cl = Dropout(0.4)(cl)\n",
    "cl = Dense(1024, activation='relu')(cl)\n",
    "cl = BatchNormalization()(cl)\n",
    "cl = Dropout(0.4)(cl)\n",
    "\n",
    "# this is the final layer; size must equal desired output size\n",
    "outputs = Dense(1, activation='sigmoid')(cl)\n",
    "model = Model(inputs, outputs)\n",
    "\n",
    "model.summary(show_trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd8c4245-b9b5-4f6e-9b14-2d3a6254a0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "learning_rate = 1e-6\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate),\n",
    "    loss=BinaryCrossentropy(from_logits=False),\n",
    "    metrics=[BinaryAccuracy()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cc7733d2-f771-4e44-a83d-100f9aecda12",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_callback = ModelCheckpoint(\n",
    "    filepath=os.path.join(os.getcwd(), checkpoint_path),\n",
    "    save_weights_only=True,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "113d2a51-b77d-48e8-b8fd-bc0615302664",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "latest = latest_checkpoint(os.path.join(os.getcwd(), checkpoint_path))\n",
    "print(latest)\n",
    "#model.load_weights(latest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c573bfc9-c7a5-41f4-95bf-5df02f324140",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\scout\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m2874/2874\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 198ms/step - binary_accuracy: 0.5174 - loss: 0.9797  \n",
      "Epoch 1: saving model to D:\\scout\\Code\\fakereal\\models\\checkpoints/mobilenetv3small/cp-0001.weights.h5\n",
      "\u001b[1m2874/2874\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m719s\u001b[0m 249ms/step - binary_accuracy: 0.5174 - loss: 0.9797 - val_binary_accuracy: 0.4942 - val_loss: 1.1121\n",
      "Epoch 2/10\n",
      "\u001b[1m   1/2874\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:11\u001b[0m 108ms/step - binary_accuracy: 0.6250 - loss: 0.8070"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\scout\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\epoch_iterator.py:107: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self._interrupted_warning()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2: saving model to D:\\scout\\Code\\fakereal\\models\\checkpoints/mobilenetv3small/cp-0002.weights.h5\n",
      "\u001b[1m2874/2874\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 36ms/step - binary_accuracy: 0.6250 - loss: 0.8070 - val_binary_accuracy: 0.4945 - val_loss: 1.1127\n",
      "Epoch 3/10\n",
      "\u001b[1m2874/2874\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - binary_accuracy: 0.5372 - loss: 0.8970  \n",
      "Epoch 3: saving model to D:\\scout\\Code\\fakereal\\models\\checkpoints/mobilenetv3small/cp-0003.weights.h5\n",
      "\u001b[1m2874/2874\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m520s\u001b[0m 181ms/step - binary_accuracy: 0.5372 - loss: 0.8970 - val_binary_accuracy: 0.4934 - val_loss: 1.0382\n",
      "Epoch 4/10\n",
      "\u001b[1m   1/2874\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:46\u001b[0m 100ms/step - binary_accuracy: 0.3750 - loss: 0.9877\n",
      "Epoch 4: saving model to D:\\scout\\Code\\fakereal\\models\\checkpoints/mobilenetv3small/cp-0004.weights.h5\n",
      "\u001b[1m2874/2874\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 35ms/step - binary_accuracy: 0.3750 - loss: 0.9877 - val_binary_accuracy: 0.4940 - val_loss: 1.0413\n",
      "Epoch 5/10\n",
      "\u001b[1m2874/2874\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - binary_accuracy: 0.5700 - loss: 0.8278  \n",
      "Epoch 5: saving model to D:\\scout\\Code\\fakereal\\models\\checkpoints/mobilenetv3small/cp-0005.weights.h5\n",
      "\u001b[1m2874/2874\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m531s\u001b[0m 185ms/step - binary_accuracy: 0.5700 - loss: 0.8278 - val_binary_accuracy: 0.4858 - val_loss: 1.0589\n",
      "Epoch 6/10\n",
      "\u001b[1m   1/2874\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:16\u001b[0m 110ms/step - binary_accuracy: 0.6250 - loss: 0.7003\n",
      "Epoch 6: saving model to D:\\scout\\Code\\fakereal\\models\\checkpoints/mobilenetv3small/cp-0006.weights.h5\n",
      "\u001b[1m2874/2874\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 37ms/step - binary_accuracy: 0.6250 - loss: 0.7003 - val_binary_accuracy: 0.4887 - val_loss: 1.0492\n",
      "Epoch 7/10\n",
      "\u001b[1m2874/2874\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - binary_accuracy: 0.5920 - loss: 0.7738  \n",
      "Epoch 7: saving model to D:\\scout\\Code\\fakereal\\models\\checkpoints/mobilenetv3small/cp-0007.weights.h5\n",
      "\u001b[1m2874/2874\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m541s\u001b[0m 188ms/step - binary_accuracy: 0.5920 - loss: 0.7738 - val_binary_accuracy: 0.4906 - val_loss: 1.0273\n",
      "Epoch 8/10\n",
      "\u001b[1m   1/2874\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:27\u001b[0m 114ms/step - binary_accuracy: 0.5000 - loss: 0.6885\n",
      "Epoch 8: saving model to D:\\scout\\Code\\fakereal\\models\\checkpoints/mobilenetv3small/cp-0008.weights.h5\n",
      "\u001b[1m2874/2874\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 39ms/step - binary_accuracy: 0.5000 - loss: 0.6885 - val_binary_accuracy: 0.4897 - val_loss: 1.0273\n",
      "Epoch 9/10\n",
      "\u001b[1m2874/2874\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - binary_accuracy: 0.6265 - loss: 0.7186  \n",
      "Epoch 9: saving model to D:\\scout\\Code\\fakereal\\models\\checkpoints/mobilenetv3small/cp-0009.weights.h5\n",
      "\u001b[1m2874/2874\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m525s\u001b[0m 183ms/step - binary_accuracy: 0.6265 - loss: 0.7186 - val_binary_accuracy: 0.4928 - val_loss: 0.9949\n",
      "Epoch 10/10\n",
      "\u001b[1m   1/2874\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:45\u001b[0m 99ms/step - binary_accuracy: 0.6250 - loss: 0.6550\n",
      "Epoch 10: saving model to D:\\scout\\Code\\fakereal\\models\\checkpoints/mobilenetv3small/cp-0010.weights.h5\n",
      "\u001b[1m2874/2874\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 36ms/step - binary_accuracy: 0.6250 - loss: 0.6550 - val_binary_accuracy: 0.4945 - val_loss: 0.9964\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=epochs,\n",
    "    steps_per_epoch=(train_generator.samples // train_generator.batch_size),\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=(val_generator.samples // val_generator.batch_size),\n",
    "    callbacks=[checkpoint_callback],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f8f08cb2-8c96-47e7-88e5-b11bfe2c52d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1118/1118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 102ms/step - binary_accuracy: 0.5019 - loss: 0.9852\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9963750243186951, 0.49452146887779236]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(val_generator, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bcb72089-6fea-4933-bd0e-a4061c46072d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(f\"{output_dir}/deepfake-{model_name}.keras\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
